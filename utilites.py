#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Thu Mar  8 16:19:06 2018

@author: Zaid
"""



import networkx as nx
import numpy as np
import subprocess
import re
import datetime
import math
from itertools import permutations, combinations
import random
import copy
import operator
from networkx.algorithms import community
from collections import deque
#import nxmetis
from colorama import Fore, Back, Style
import jains as JM
import traffic as TF
from itertools import permutations
import os
#import tqdm
import re

#path = "/home/zaid-pc/Documents/Dropbox/area/dragonfly_project/dragonfly/booksim/src/"
path = "/home/oem/Dropbox/area/dragonfly_project/dragonfly/new_booksim/booksim/src/"
#path = '/home/zaid/new_booksim/booksim/src/'
#path = '/home/zaid/DF_project/dragonfly/booksim/src/'
def run_booksim(file,a,g,p):
    # filename = input("File name: ")
    routing = ['ugall_dragonfly','ugall','min','vlb','par_dragonfly']
    routing_vc = [3,7,3,7,7]
    pattren = ['uniform','randperm','shift']

    filename = 'examples/anynet/dfly_anynet/dfly_anynet_config'
    rate = 0.1
    throuputs = {}
    def pInject(line):
        pInject.rate += rate
        if pInject.rate > 1.0:
            pInject.rate = 1.0
        return line[:line.index('=') + 1] + str(pInject.rate) + line[line.index(';'):]
    
        
    for t in pattren:
        
        rate = 0.1
        
        throuputs[t] = dict() 
        for indx,r in enumerate(routing):
            throuputs[t][r] = dict() 
            print(r,t,'\n',file)    
            pInject.rate = 0.0
        
            #for filename in ['examples/df', 'examples/anynet/df']:
            run = True
            # print(filename)
            perams = [['injection_rate', '='+str(rate)],
                      ['a                     = ' ,a],
                      ['g                     = ',g],
                      ['network_file',"="+file],
                      ['routing_function      =',r],
                      ['traffic               =',t],
                      ['p                     = ',p],
                      ['shift_offset          = ',a*p],
                      ['num_vcs               = ',routing_vc[indx]]]
        
            newFile = ""
            for line in open(path + filename, 'r'):
                for match, value in perams:
                    if match in line:
                        line = match +str(value)+";\n"
                        break
                newFile += line
                
            with open(path + filename, 'w') as fd:
                fd.write(newFile)
            #return
            perams = [['injection_rate', pInject]]
           
            preoutput = ''
            
            while run:
                newFile = ""
                for line in open(path + filename, 'r'):
                    for match, funct in perams:
                        if match in line:
                            line = funct(line)
                    newFile += line
        
                with open(path + filename, 'w') as fd:
                    fd.write(newFile)
        
                cmdName = path + 'booksim'
                print(round(pInject.rate,2))
                proc = subprocess.run([cmdName, path + filename], stdout=subprocess.PIPE)
                # print("saturated at ",pInject.rate)
                bookOut = proc.stdout.decode('utf-8')
                
                print(bookOut)
                
                if "Error:" in bookOut or "error" in bookOut:
                    print("error",r,t,bookOut,'\n')
                    throuputs[t][r] = 0
                    break
                    
                if 'Aborting simulation' in bookOut:
                    if rate == 0.01:
                        
                        run = False
                       
                        print("saturated at %.2f " % (pInject.rate - 0.01))
                        throuputs[t][r]['s'] = pInject.rate - 0.01
                        
#                        results = re.findall(r'(Packet latency average)( = )(\d+\.\d+)',preOutput)
#                        results2 = re.findall(r'(Network latency average)( = )(\d+\.\d+)',preOutput)
#                        throuputs[t][r]['pl'] =float(results[-1][2])
#                        throuputs[t][r]['nl'] =float(results2[-1][2])
                        pInject.rate = 0.10
                        rate = 0.1
                    #return pInject.rate - 0.01
                        break
                    
                    elif pInject.rate == 0.1:
                       pInject.rate == 0.01
                       rate = 0.01
                    
                    else:
                       pInject.rate -= 0.1
                       rate = 0.01
                
                if 'Segmentation fault' in bookOut:
                    run = False
                    pInject.rate = 0.10
                    print("Segmentation fault")
                    throuputs[t][r]['s'] = 0
#                    throuputs[t][r]['pl'] = 0
#                    throuputs[t][r]['nl'] = 0
                    rate = 0.1
                    #return pInject.rate - 0.01
                    break
                    
                #if pInject.rate > 0.89:
                    #run = False
                    #rate = 0.01 
                    #print("saturated at 1")
                    #throuputs[t][r] = 1
                    #return pInject.rate - 0.01
                if pInject.rate > 0.99:
                    run = False
                    pInject.rate = 0.10
#                    results = re.findall(r'(Packet latency average)( = )(\d+\.\d+)',bookOut)
#                    results2 = re.findall(r'(Network latency average)( = )(\d+\.\d+)',bookOut)
#                    throuputs[t][r]['pl'] =float(results[-1][2])
#                    throuputs[t][r]['nl'] =float(results2[-1][2])
                    #print(results)
                    print("saturated at 1 ")
                    throuputs[t][r]['s'] = 1.0
                    rate = 0.1
                    #return pInject.rate - 0.01
                    break
                    
                preOutput = bookOut      
                
    return throuputs

def run_booksim(file,a,g,p):
    # filename = input("File name: ")
    routing = ['ugall_dragonfly','ugall','min','vlb','par_dragonfly']
    routing_vc = [3,7,3,7,7]
    pattren = ['uniform','randperm','shift']

    filename = 'examples/anynet/dfly_anynet/dfly_anynet_config'
    rate = 0.1
    throuputs = {}
    def pInject(line):
        pInject.rate += rate
        if pInject.rate > 1.0:
            pInject.rate = 1.0
        return line[:line.index('=') + 1] + str(pInject.rate) + line[line.index(';'):]
    
        
    for t in pattren:
        
        rate = 0.1
        
        throuputs[t] = dict() 
        for indx,r in enumerate(routing):
            throuputs[t][r] = dict() 
            print(r,t,'\n',file)    
            pInject.rate = 0.0
        
            #for filename in ['examples/df', 'examples/anynet/df']:
            run = True
            # print(filename)
            perams = [['injection_rate', '='+str(rate)],
                      ['a                     = ' ,a],
                      ['g                     = ',g],
                      ['network_file',"="+file],
                      ['routing_function      =',r],
                      ['traffic               =',t],
                      ['p                     = ',p],
                      ['shift_offset          = ',a*p],
                      ['num_vcs               = ',routing_vc[indx]]]
        
            newFile = ""
            for line in open(path + filename, 'r'):
                for match, value in perams:
                    if match in line:
                        line = match +str(value)+";\n"
                        break
                newFile += line
                
            with open(path + filename, 'w') as fd:
                fd.write(newFile)
            #return
            perams = [['injection_rate', pInject]]
           
            preoutput = ''
            
            while run:
                newFile = ""
                for line in open(path + filename, 'r'):
                    for match, funct in perams:
                        if match in line:
                            line = funct(line)
                    newFile += line
        
                with open(path + filename, 'w') as fd:
                    fd.write(newFile)
        
                cmdName = path + 'booksim'
                print(round(pInject.rate,2))
                proc = subprocess.run([cmdName, path + filename], stdout=subprocess.PIPE)
                # print("saturated at ",pInject.rate)
                bookOut = proc.stdout.decode('utf-8')
                
                print(bookOut)
                
                if "Error:" in bookOut or "error" in bookOut:
                    print("error",r,t,bookOut,'\n')
                    throuputs[t][r] = 0
                    break
                    
                if 'Aborting simulation' in bookOut:
                    if rate == 0.01:
                        
                        run = False
                       
                        print("saturated at %.2f " % (pInject.rate - 0.01))
                        throuputs[t][r]['s'] = pInject.rate - 0.01
                        
#                        results = re.findall(r'(Packet latency average)( = )(\d+\.\d+)',preOutput)
#                        results2 = re.findall(r'(Network latency average)( = )(\d+\.\d+)',preOutput)
#                        throuputs[t][r]['pl'] =float(results[-1][2])
#                        throuputs[t][r]['nl'] =float(results2[-1][2])
                        pInject.rate = 0.10
                        rate = 0.1
                    #return pInject.rate - 0.01
                        break
                    
                    elif pInject.rate == 0.1:
                       pInject.rate == 0.01
                       rate = 0.01
                    
                    else:
                       pInject.rate -= 0.1
                       rate = 0.01
                
                if 'Segmentation fault' in bookOut:
                    run = False
                    pInject.rate = 0.10
                    print("Segmentation fault")
                    throuputs[t][r]['s'] = 0
#                    throuputs[t][r]['pl'] = 0
#                    throuputs[t][r]['nl'] = 0
                    rate = 0.1
                    #return pInject.rate - 0.01
                    break
                    
                #if pInject.rate > 0.89:
                    #run = False
                    #rate = 0.01 
                    #print("saturated at 1")
                    #throuputs[t][r] = 1
                    #return pInject.rate - 0.01
                if pInject.rate > 0.99:
                    run = False
                    pInject.rate = 0.10
#                    results = re.findall(r'(Packet latency average)( = )(\d+\.\d+)',bookOut)
#                    results2 = re.findall(r'(Network latency average)( = )(\d+\.\d+)',bookOut)
#                    throuputs[t][r]['pl'] =float(results[-1][2])
#                    throuputs[t][r]['nl'] =float(results2[-1][2])
                    #print(results)
                    print("saturated at 1 ")
                    throuputs[t][r]['s'] = 1.0
                    rate = 0.1
                    #return pInject.rate - 0.01
                    break
                    
                preOutput = bookOut      
                
    return throuputs            
def get_list_of_test_files(cwd=None):
    if not cwd:
        cwd = os.getcwd()
        
    directory = os.fsencode(cwd)
    list_of_testing_files = list()
    for file in os.listdir(directory):
        filename = os.fsdecode(file)
        if filename.endswith(".txt"):
            list_of_testing_files.append(filename)
            continue
        else:
            continue
        
    return list_of_testing_files   
    
'''
write a topology in booksim format
anynet format
'''


def write_adj_list_to_a_file_booksim(G, name, h,n):
    nodes = sorted(list(G.nodes()))
    # print(nodes)
    server_count = 0
    name = path + "examples/anynet/" + str(name)
    with open(name, 'w') as fd:

        for node in nodes:
            fd.write("router " + str(node) + " ")

            for i in range(h):
                fd.write("node " + str(server_count) + " ")
                server_count += 1
            # fd.write("\n")

            for n in sorted(list(G.neighbors(node))):
                fd.write("router " + str(n) + " ")
            fd.write("\n")

'''
write a topology in booksim format
juan format
'''
def write_to_a_file_booksim(G, name, a,h,n,g,p):

    name = "testcases/32/" + str(name)+"_("+str(a)+"_"+str(h)+"_"+str(g)+"_"+str(p)+").txt"
#    for d in G.edges(data=True):
#        print(d)  
    with open(name, 'w') as fd:
        
        for node in range(n):
            fd.write("router " + str(node) + " ")

            for ngbr in G.neighbors(node):
                #print(node,ngbr)
                if ngbr >= n:
                    fd.write("node " + str(ngbr - n) + " ")
                else:
                    #print("weight = ",G[node][ngbr]['w'])
                    for _ in range(G[node][ngbr]['cap']):
                        fd.write("router " + str(ngbr) + " "+ str(G[node][ngbr]['w'])+" ")
            fd.write("\n")
'''
get the degree with  a redundent links
'''


def get_degree(G, sw, global_links):

    neighburs_list = list(G.neighbors(sw))

    degree = 0

    for n in neighburs_list:
        d1 = d2 = 0
        if (sw, n) in global_links and G[sw][n]['type'] == 'global':
            d1 = global_links[(sw, n)]
        if (n, sw) in global_links and G[sw][n]['type'] == 'global':
            d2 = global_links[(n, sw)]
        degree += max(d1, d2)
    # print("nx degree: ",G.degree(sw)," our degree : ",degree)
    return degree
'''
get the degree with  a redundent links
'''


def get_degree_global(G, sw, global_links):

    neighburs_list = list(G.neighbors(sw))

    degree = 0

    for n in neighburs_list:
        d1 = d2 = 0
        if (sw, n) in global_links:
            d1 = global_links[(sw, n)]
        if (n, sw) in global_links:
            d2 = global_links[(n, sw)]
        degree += max(d1, d2)
    # print("nx degree: ",G.degree(sw)," our degree : ",degree)
    return degree

def get_degree_global2(G, sw, global_links):

    neighburs_list = list(G.neighbors(sw))

    degree = 0

    for n in neighburs_list:
        d1 = d2 = 0
        if (sw, n) in global_links:
            d1 = global_links[(sw, n)]['width']
        if (n, sw) in global_links:
            d2 = global_links[(n, sw)]['width']
        degree += max(d1, d2)
    # print("nx degree: ",G.degree(sw)," our degree : ",degree)
    return degree

def get_balance_condition(a, h, g):
    t = (a * h) / (g - 1)
    alpha = (t * (g - 1)) / (a * (a - 1))
    b = 1 + (alpha * ((a * (a - 1)) / t))
    print("t = ", t, "alpha = ", alpha, "b = ", b)
    return t
    # print("t = ", t, "alpha = ", alpha, "b = ", b)


def get_bisect(G):
    #return nxmetis.partition(G, 2)[0]
    pass

def link_usage(G, global_links, local_links, aggr , src_dest_list,paths_fyod = None,a= None,g=None):
    all_pathes = []

    #    counts_pa ths_len = [0] * 10
    #    count_pathes = 0
    results = {'name': aggr, 'avr_l_local': 0, 'avr_l_global': 0, 'over_all_load': 0, 'local_max': 0, 'global_max': 0,
               'local_min': 0, 'global_min': 0, 'link_load_local': [], 'link_load_global': [], 'link_load_all': 0,
               'global_links': global_links, 'local_links': local_links, 'count_pathes': 0, 'counts_paths_len': {},
               'sum_load_local': 0, 'sum_load_global': 0, 'g_l_count': 0, 'l_l_count': 0,'nodes_with_more_sh':{},'max_flow':[],'perm_thr':0}
    count = 0

#    for src in list(G.nodes()):
#        for dest in list(G.nodes()):
    for src , dest in src_dest_list:
        if src == dest:
            continue
        results['max_flow'].append(0)
        count += 1
        
        if not paths_fyod: 
            all_pathes = list(nx.all_shortest_paths(G, source=src, target=dest, weight='w'))
        else:
            all_pathes = paths_fyod[src][dest]            
            #print(all_pathes,"\n",list(nx.all_shortest_paths(G, source=src, target=dest, weight='w')))    
        pathlen = len(all_pathes[0]) - 1
        if len(all_pathes) in results['nodes_with_more_sh']:
            results['nodes_with_more_sh'][len(all_pathes)] += 1
        else:
            results['nodes_with_more_sh'][len(all_pathes)] = 1


        if pathlen in results['counts_paths_len']:
            results['counts_paths_len'][pathlen] += 1
        else:
            results['counts_paths_len'][pathlen] = 1

        max_edg_wight_list = [1] * len(all_pathes)

        for indx,path in enumerate(all_pathes):
            # total_load += (len(path)-1)/len(all_pathes)
            max_edg_wight = 1
            for n in range(len(path) - 1):

                if (path[n], path[n + 1]) in results['local_links']:
                    max_edg_wight =  max(results['local_links'][(path[n], path[n + 1])]['w'],max_edg_wight)

                elif (path[n], path[n + 1]) in results['global_links']:
                    max_edg_wight =  max(results['global_links'][(path[n], path[n + 1])]['w'],max_edg_wight)

            max_edg_wight_list[indx] = max_edg_wight

        for indx ,path in enumerate(all_pathes):
            for n in range(len(path) - 1):

                if (path[n], path[n + 1]) in results['local_links']:
                    results['local_links'][(path[n], path[n + 1])]['count'] += 1
                    results['local_links'][(path[n], path[n + 1])]['load'] += (max_edg_wight_list[indx] / sum(max_edg_wight_list)) #* results['local_links'][(path[n], path[n + 1])]['w'])
                elif (path[n], path[n + 1]) in results['global_links']:

                    results['global_links'][(path[n], path[n + 1])]['count'] += 1
                    results['global_links'][(path[n], path[n + 1])]['load'] += (
                    max_edg_wight_list[indx] / sum(max_edg_wight_list)) #* results['global_links'][(path[n], path[n + 1])]['w'])
                else:
                    print("edge (", path[n], ",", path[n + 1] ,") not exist,",a,g)
                    raise Exception('unknown error',aggr)

                        # print("src",src , "dest",dest ,"\npaths\n",all_pathes,"\n\n")
    # print("total load :",total_load)
    results['local_min'] = G.number_of_nodes()
    results['global_min'] = G.number_of_nodes()

    results['g_l_count'] = (sum([x['w'] for x in results['global_links'].values()]))
    results['l_l_count'] = (sum([x['w'] for x in results['local_links'].values()]))

    for edg in results['local_links']:
        # results['local_links'][edg]['load'] = (results['local_links'][edg]['load'] # / results['local_links[edg]']['w'])
        results['sum_load_local'] += results['local_links'][edg]['load']
        results['local_min'] = min(results['local_min'], results['local_links'][edg]['load'])
        results['local_max'] = max(results['local_max'], results['local_links'][edg]['load'])

    results['avr_l_local'] = results['sum_load_local'] / results['l_l_count']

    for edg in global_links:
        # global_links[edg]['load'] = (global_links[edg]['load'] / global_links[edg]['w'])
        results['sum_load_global'] += results['global_links'][edg]['load']
        results['global_max'] = max(results['global_max'], results['global_links'][edg]['load'])
        results['global_min'] = min(results['global_min'], results['global_links'][edg]['load'])

    results['avr_l_global'] = results['sum_load_global'] / results['g_l_count']

    results['over_all_load'] = (results['sum_load_local'] + results['sum_load_global']) / (results['g_l_count'] + results['l_l_count'])

    results['link_load_all'] = np.array(
        [x['load'] for x in results['global_links'].values()] + [x['load'] for x in results['local_links'].values()])
    results['link_load_local'] = np.array([x['load'] for x in results['local_links'].values()])
    results['link_load_global'] = np.array([x['load'] for x in results['global_links'].values()])

    for e1, e2 in list(G.edges()):

        if G[e1][e2]['type'] == "local":
            color1 = (results['local_links'][(e1, e2)]['load'] - results['local_min']) / (
            results['local_max'] - results['local_min'] + 0.001)
            color2 = (results['local_links'][(e2, e1)]['load'] - results['local_min']) / (
            results['local_max'] - results['local_min'] + 0.001)
            G[e1][e2]['color'] = (0.5, color1, 0.0)

        else:
            color1 = (results['global_links'][(e1, e2)]['load'] - results['global_min']) / (
            results['global_max'] - results['global_min'] + 0.001)
            color2 = (results['global_links'][(e2, e1)]['load'] - results['global_min']) / (
            results['global_max'] - results['global_min'] + 0.001)
            G[e1][e2]['color'] = (color1, 0.5, 0.0)



    return G, results
'''
print out the final results
'''

def print_the_result(G, results, gl_arrangmnt, g, a):

    print(Style.RESET_ALL)
    print(Style.BRIGHT)
    print(Back.MAGENTA)
    print(
        Fore.GREEN + "Topology name : Dragonfly ({})\nNumber of Groups:{}\nNnumber of Swithes: {}\nSwitch per Group:{}\n".format(
            gl_arrangmnt, g, G.number_of_nodes(), a))
    print(Back.GREEN)
    print(Style.NORMAL)
    print(Fore.RED + "####Global links statistics###\n")
    print(Style.RESET_ALL)
    print(Fore.BLUE)
    print(Style.BRIGHT)
    print("total number of global links :", sum([x['cap'] for x in results['global_links'].values()]))
    print("avrage link load (global): ", results['avr_l_global'])
    print(Fore.MAGENTA + "max link load (global) : ", results['global_max'])
    print(Fore.BLUE)
    print("min link load (global) : ", results['global_min'])
    print("links varience (global):", np.var(results['link_load_global']))
    print("total load on (glbal):", results['sum_load_global'])
    print("total links :", results['g_l_count'])
    print(Style.RESET_ALL)
    print(Fore.RED + "###############################\n")
    print(Back.GREEN)
    print("####Local links statistics###")
    print(Style.RESET_ALL)
    print(Fore.BLUE)
    print(Style.BRIGHT)
    print("total number of local links :", sum([x['cap'] for x in results['local_links'].values()]))
    print("avrage link load (local): ", results['avr_l_local'])
    print(Fore.MAGENTA + "max link load (local) : ", results['local_max'])
    print(Fore.BLUE)
    print("min link load (local) : ", results['local_min'])
    print("links varience (local):", np.var(results['link_load_local']))
    print("total load on (local)", results['sum_load_local'])
    print("total links :", results['l_l_count'])
    print(Style.RESET_ALL)
    print(Fore.RED + "\n###############################\n")
    print(Back.GREEN)
    print("####overall links statistics###")
    print(Style.RESET_ALL)
    print(Fore.BLUE)
    print(Style.BRIGHT)
    print("avrage link load (overall)= ", results['over_all_load'])
    print("links varience (overall):", np.var(results['link_load_all']))
    print(Style.RESET_ALL)
    print(Fore.RED + "\n###############################\n")
    print(Back.GREEN)
    print(Fore.RED + "####pathes  statistics###\n")
    print(Style.RESET_ALL)
    print(Fore.BLUE)
    print(Style.BRIGHT)
    print("\nMax flow :" ,min(results['max_flow']))
    for x in results['counts_paths_len']:
        print("shortest path with %d hope(s):  %d out of %d pathes = %.2f  " % (x, results['counts_paths_len'][x],
                                                                                (a * g) * (a * g - 1),
                                                                                results['counts_paths_len'][x] / (
                                                                                        (a * g) * (a * g - 1))))
    for x in results['nodes_with_more_sh']:
        print("number of communication with %d path(s) :  %d out of %d pathes = %.2f  " %
        (x, results['nodes_with_more_sh'][x],
        sum(results['nodes_with_more_sh'].values()),
        results['nodes_with_more_sh'][x] / (
            sum(results['nodes_with_more_sh'].values()))))
    #results['bw'] = get_bisect(G)
    results['bw'] = "skipped"
    print("The Bisection bandwidth : ", results['bw'])
    # calculate avrage shortest path based on moore bound
    x = 0
    opt_avr_s_p = []
    n = a * g
    sd = n * (n - 1)
    degree = (a // 2) + (a - 1)

    path_length = 1
    while sum(opt_avr_s_p) < sd:
        opt_avr_s_p += [min((n * degree) ** path_length, sd - sum(opt_avr_s_p)) * path_length]
        path_length += 1

    results['avr_shp_opt'] = sum(opt_avr_s_p) / sd
    print("optimal avrage shortest path:", results['avr_shp_opt'])
    print("optimal shortest path:")
    results['avr_shp'] = sum([results['counts_paths_len'][x] * x for x in results['counts_paths_len']]) / (
            (a * g) * (a * g - 1))
    print("avrage shortest path  : ", results['avr_shp'])
    print("all to all connections : ", ((a * g) * (a * g - 1)))
    # for edg, data in results['global_links'].items():

    print(Fore.RED + "\n###############################\n")

#    file_name = results['name'] + "_" + str(results['a']) + "_" + str(results['g'])
#
#    with open(file_name, 'w') as fd:
#        fd.write(
#            str(results['a']) + " " + str(results['a']) + " " + str(results['a'] // 2) + " " + str(results['g']) + "\n")
#
#        for edg, data in results['global_links'].items():
#            for x in range(data['w']):
#                sg = edg[0] // results['a']
#                dg = edg[1] // results['a']
#                ss = edg[0] % results['a']
#                ds = edg[1] % results['a']




def get_asp(result_dict,a,g):
    
    x = 0
    opt_avr_s_p = []
    n = a * g
    sd = n * (n - 1)
    degree = (a // 2) + (a - 1)

    path_length = 1
    while sum(opt_avr_s_p) < sd:
        opt_avr_s_p += [min((n * degree) ** path_length, sd - sum(opt_avr_s_p)) * path_length]
        path_length += 1
    
    opt_asp = sum(opt_avr_s_p) / sd
        
    for k,v in result_dict.items():
        if v['r']:
             v['lb']['avr_shp'] = sum([ v['lb']['counts_paths_len'][x] * x for x in  v['lb']['counts_paths_len']]) / (
                (a * g) * (a * g - 1))
             v['lb']['avr_shp_opt'] = opt_asp

# check if graphs are isomorphic         
def check_isomorphics(graphs):

    for i in range(len(graphs) - 1):
        for j in range(i + 1, len(graphs)):
            if nx.is_isomorphic(graphs[i][0], graphs[j][0]):
                print(graphs[i][1], " and ", graphs[j][1], 'is isomorphic')


def validate_DF(G,global_links,local_links,a,g):
    for node in list(G.nodes()):
        if not get_degree_global2(G, node, global_links) == a // 2:
        
              return False

    for edg in global_links:
        if ((edg[0], edg[1]) in local_links):
            return False
    
    if (sum([x['width'] for x in global_links.values()]) != a*g*(a//2)):
        return False
    
    if not nx.is_connected(G):
        return False

    return True

def get_thrght(result_dicti , n, nodes,name,pl=None,shift = 0, x=1):

    #thr = [[] for x in range(len(result_dicti))]
    
    for i in range(n):
        traf = TF.traffic_pattrens(nodes,name, shift ,x)
        for arrg, values in result_dicti.items():
            if values['r']:
                #print(traf,"\n\n\n",values['paths'])
                values['tr_thg'][name].append(JM.jains_model(values['G'],traf,values['paths']))
                #print(values['tr_thg'][name])

    #return thr
    
    
def get_tf_from_file(fname):
    sd = []
    
    with open(fname) as tf:
        links = tf.readlines()
    
        for l in links:
            l = list(map(int, (l.split(' '))))
            sd.append((l[0],l[1]))
    
    return sd
    
# form networkx with midification to store all shortest paths     
def floyd_warshall_predecessor_and_distance(G, weight='weight'):

    from collections import defaultdict

    dist = defaultdict(lambda : defaultdict(lambda: float('inf')))
    
    dist_paths =  defaultdict(lambda : defaultdict(lambda: list()))
    
    for u in G:
        dist[u][u] = 0
    pred = defaultdict(dict)

    undirected = not G.is_directed()
    for u,v,d in G.edges(data=True):
        e_weight = d.get(weight, 1.0)
        dist[u][v] = min(e_weight, dist[u][v])
        pred[u][v] = u
        dist_paths[u][v].append(u)
        #dist_paths[u][v] = list()
        if undirected:
            dist[v][u] = min(e_weight, dist[v][u])
            pred[v][u] = v
            dist_paths[v][u].append(v)
            #dist_paths[v][u] = list()
        
    #for w in G:
    for w in tqdm.tqdm(G,desc='dirs'):
        for u in G:
            for v in G:
                dist_paths[v][u]
                #print("u:",u," ,v:",v ," = ",dist[u][v])
                if dist[u][v] > dist[u][w] + dist[w][v]:
                    dist_paths[u][v].clear()
                    dist_paths[u][v].append(w)
                    dist[u][v] = dist[u][w] + dist[w][v]
                    pred[u][v] = pred[w][v]
                
                elif  (dist[u][v] == dist[u][w] + dist[w][v]) and u!= w and v != w and  dist[u][v] != float('inf'):
                    dist_paths[u][v].append(w)
                                        
          
    return dict(pred),dict(dist) ,dict(dist_paths)
    
   
def remove_dup_from_path(path):
    seen = set()
    l = list()
    for x in path:
        if not (x in seen or seen.add(x)):
            l.append(x)
    return l        
    #return [x for x in path if not (x in seen or seen.add(x))]
    
def floyd_warshall_all_pairs_sp(G, weight='w',perm_list=None,n=None):
    pred,dist,dist_paths = floyd_warshall_predecessor_and_distance(G,weight = weight)
    
    if not n:
        n = G.number_of_nodes()
    
    all_paths_matrix = [ ]
    for x in range(n):
        all_paths_matrix.append([ [] for _ in range(n) ])
    
    if not perm_list: 
        perm_list = list(permutations(list(range(n)),2)) 
    #print(all_paths_matrix)
    #for p in dist_paths.values():
        #print(p)
        
    def GetPath(s,d): 
        #pass
        all_paths = []
        if dist_paths[s][d]:
            
            for k in dist_paths[s][d]:  
                #print(k,s,d)
                if k == s or k == -1:
                    all_paths.append([s,d])
                
                else: 
                    paths_I_K = GetPath(s,k) 
                    paths_K_J = GetPath(k,d)
                    for path1 in paths_I_K:
                        for path2 in paths_K_J:
                            all_paths.append(remove_dup_from_path(path1 + path2))
                            #print(all_paths[-1])

        #print(GetPath(s, d)) 
                 
        return all_paths
    #seen = set()
#    for s in range(n):
#      all_paths_matrix[s][s] = [[s]]
                  
    for s,d in tqdm.tqdm(perm_list):
        if s == d:
            all_paths_matrix[s][d] = [[s]]
            continue
        all_paths_matrix[s][d]= GetPath(s, d)
        #seen.add((s,d),(d,s))

    #print(all_paths_matrix)
    return all_paths_matrix



def print_the_final_result(result_dicti,throughput_test):
    print(Style.BRIGHT)

    print (Back.CYAN + "{:<20} {:<30} {:<20} {:<20} {:<20} {:<20} {:<20} {:<20} {:<20} ".format(
                            'config (a,h,g)', 'Arrangment Name',
                            'max load(g/l)', 'avg load (g/l/all)'
                             , 'avg sh path',
                            'avg sh path (opt)'
                            ,throughput_test[0],throughput_test[1],throughput_test[2]))
    
    print(Style.RESET_ALL)
    
    for i, v in result_dicti.items():
        if v['r']:
            print ("{:<20} {:<20} {:<20} {:<20} {:<20} {:<20} {:<20} {:<20} {:<20} ".format
                (
                "\t(" + str(v['lb']['a']) + ',' + 
                str(v['lb']['a'] // 2) + ',' + 
                str(v['lb']['g']) + ')',
                v['lb']['name'],
                str(round(v['lb']['global_max'], 2))+'/'+
                str(round(v['lb']['local_max'], 2)),
                str(round(v['lb']['avr_l_global'], 2))+'/'+
                str(round(v['lb']['avr_l_local'], 2))+"/"+
                str(round(v['lb']['over_all_load'],2)),
                round(v['lb']['avr_shp'], 2),
                round(v['lb']['avr_shp_opt'], 2),
                round(sum(v['tr_thg'][throughput_test[0]])/len(v['tr_thg'][throughput_test[0]]),2),
                round(sum(v['tr_thg'][throughput_test[1]])/len(v['tr_thg'][throughput_test[1]]),2),
                round(sum(v['tr_thg'][throughput_test[2]])/len(v['tr_thg'][throughput_test[2]]),2)
                ))    
        else:
            print ("{:<20} {:<30} {:<20} {:<20} {:<20} {:<20} {:<20} {:<20} {:<20} {:<20} {:<20} ".format
                 (
                 "\t(" + str(v['lb']['a']) + ',' + 
                 str(v['lb']['a'] // 2) + ',' + 
                 str(v['lb']['g']) + ')'+i))
        
def print_the_final_result_to_file(result_dicti,throughput_test,a=None,g=None):
    

    import os
    import csv
    
    filename = "results_pc-1_("+str(a)+").csv"
    n = 0
    s = 0
    if os.path.exists(filename):
        #s += 1
        #filename = "results_laptop_("+str(a)+").csv"
        append_write = 'a' # append if already exists
        n = 1
    else:
        append_write = 'w' # make a new file if not
       
    with open(filename, append_write, newline='') as csvfile:
                #writer = csv.writer(csv_file, delimiter=',')
                fieldnames = ['config (a,h,g)', 'Arrangment Name','max load(g/l)','avg load (g/l/all)','avg sh path','avg sh path (opt)',throughput_test[0],throughput_test[1],throughput_test[2]]
                
                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
                
                if not n:
                    writer.writeheader()
                
                for k ,v in result_dicti.items():
                     if v['r']:
                        writer.writerow({
                                'config (a,h,g)':   "(" + str(v['lb']['a']) + ',' + 
                                                     str(v['lb']['a'] // 2) + ',' + 
                                                     str(v['lb']['g']) + ')',
                                'Arrangment Name':   v['lb']['name'],
                                'max load(g/l)':     str(round(v['lb']['global_max'], 2))+'/'+
                                                     str(round(v['lb']['local_max'], 2)),
                                'avg load (g/l/all)':str(round(v['lb']['avr_l_global'], 2))+'/'+
                                                     str(round(v['lb']['avr_l_local'], 2))+"/"+
                                                     str(round(v['lb']['over_all_load'],2)),
                                'avg sh path':       round(v['lb']['avr_shp'], 2),
                                'avg sh path (opt)': round(v['lb']['avr_shp_opt'], 2) ,
                                 throughput_test[0]: round(sum(v['tr_thg'][throughput_test[0]])/len(v['tr_thg'][throughput_test[0]]),2),
                                 throughput_test[1]: round(sum(v['tr_thg'][throughput_test[1]])/len(v['tr_thg'][throughput_test[1]]),2),
                                 throughput_test[2]: round(sum(v['tr_thg'][throughput_test[2]])/len(v['tr_thg'][throughput_test[2]]),2)
                                })
                                    
                     else:  
                        writer.writerow({
                                'config (a,h,g)':   "(" + str(v['lb']['a']) + ',' + 
                                                     str(v['lb']['a'] // 2) + ',' + 
                                                     str(v['lb']['g']) + ')',
                                'Arrangment Name':   k,
                                'max load(g/l)':     '-',
                                'avg load (g/l/all)': '-',
                                'avg sh path':       '-',
                                'avg sh path (opt)': '-' ,
                                 throughput_test[0]: '-',
                                 throughput_test[1]: '-',
                                 throughput_test[2]: '-'
                                })


##G = nx.Graph()
#
#G.add_edge(0,1,w = 1)
#G.add_edge(1,2,w = 1)
#G.add_edge(2,3,w = 1)
#G.add_edge(3,0,w = 1)
# 
#m = floyd_warshall_all_pairs_sp(G, weight='w') 
#print(floyd_warshall_all_pairs_sp(G,weight='w'))
